{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with Trajectory_Dataloader class #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME_TO_NUM = {\n",
    "    'eth': 0,\n",
    "    'hotel': 1,\n",
    "    'zara1': 2,\n",
    "    'zara2': 3,\n",
    "    'univ': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.dataset = 'eth5'\n",
    "args.test_set = 'zara1'\n",
    "args.save_dir = './output/' + args.test_set + \"/\"\n",
    "args.seq_length = 20\n",
    "args.obs_length = 20\n",
    "args.neighbor_thred = 10\n",
    "args.batch_size = 8\n",
    "args.batch_around_ped = 256\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "\n",
    "self = Object()\n",
    "self.args = args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.args.dataset == 'eth5':\n",
    "\n",
    "    self.data_dirs = ['../data/eth/univ', '../data/eth/hotel',\n",
    "                      '../data/ucy/zara/zara01', '../data/ucy/zara/zara02',\n",
    "                      '../data/ucy/univ/students001', '../data/ucy/univ/students003',\n",
    "                      '../data/ucy/univ/uni_examples', '../data/ucy/zara/zara03']\n",
    "\n",
    "    # Data directory where the pre-processed pickle file resides\n",
    "    self.data_dir = './data'\n",
    "    skip = [6, 10, 10, 10, 10, 10, 10, 10]\n",
    "\n",
    "    train_set = [i for i in range(len(self.data_dirs))]\n",
    "\n",
    "    assert args.test_set in DATASET_NAME_TO_NUM.keys(), 'Unsupported dataset {}'.format(args.test_set)\n",
    "\n",
    "    args.test_set = DATASET_NAME_TO_NUM[args.test_set]\n",
    "\n",
    "    if args.test_set == 4 or args.test_set == 5:\n",
    "        self.test_set = [4, 5]\n",
    "    else:\n",
    "        self.test_set = [self.args.test_set]\n",
    "\n",
    "    for x in self.test_set:\n",
    "        train_set.remove(x)\n",
    "\n",
    "    self.train_dir = [self.data_dirs[x] for x in train_set]\n",
    "    self.test_dir = [self.data_dirs[x] for x in self.test_set]\n",
    "    self.trainskip = [skip[x] for x in train_set]\n",
    "    self.testskip = [skip[x] for x in self.test_set]\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "self.train_data_file = os.path.join(self.args.save_dir, \"train_trajectories.cpkl\")\n",
    "self.test_data_file = os.path.join(self.args.save_dir, \"test_trajectories.cpkl\")\n",
    "self.train_batch_cache = os.path.join(self.args.save_dir, \"train_batch_cache.cpkl\")\n",
    "self.test_batch_cache = os.path.join(self.args.save_dir, \"test_batch_cache.cpkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. dataPreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setname == 'train':\n",
    "    data_dirs = self.train_dir\n",
    "    data_file = self.train_data_file\n",
    "else:\n",
    "    data_dirs = self.test_dir\n",
    "    data_file = self.test_data_file\n",
    "\n",
    "\n",
    "def load_dict(data_file):\n",
    "    f = open(data_file, 'rb')\n",
    "    raw_data = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    frameped_dict = raw_data[0]\n",
    "    pedtraject_dict = raw_data[1]\n",
    "\n",
    "    return frameped_dict, pedtraject_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameped_dict, pedtraject_dict = load_dict(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocess(self, setname):\n",
    "    '''\n",
    "    Function to load the pre-processed data into the DataLoader object\n",
    "    '''\n",
    "    if setname == 'train':\n",
    "        val_fraction = 0\n",
    "        frameped_dict = self.frameped_dict\n",
    "        pedtraject_dict = self.pedtraject_dict\n",
    "        cachefile = self.train_batch_cache\n",
    "\n",
    "    else:\n",
    "        val_fraction = 0\n",
    "        frameped_dict = self.test_frameped_dict\n",
    "        pedtraject_dict = self.test_pedtraject_dict\n",
    "        cachefile = self.test_batch_cache\n",
    "        \n",
    "    if setname != 'train':\n",
    "        shuffle = False\n",
    "    else:\n",
    "        shuffle = True\n",
    "        \n",
    "    data_index = self.get_data_index(frameped_dict, setname, ifshuffle=shuffle)\n",
    "    val_index = data_index[:, :int(data_index.shape[1] * val_fraction)]\n",
    "    train_index = data_index[:, (int(data_index.shape[1] * val_fraction) + 1):]\n",
    "    trainbatch = self.get_seq_from_index_balance(frameped_dict, pedtraject_dict, train_index, setname)\n",
    "    valbatch = self.get_seq_from_index_balance(frameped_dict, pedtraject_dict, val_index, setname)\n",
    "    trainbatchnums = len(trainbatch)\n",
    "    valbatchnums = len(valbatch)\n",
    "\n",
    "    f = open(cachefile, \"wb\")\n",
    "    pickle.dump((trainbatch, trainbatchnums, valbatch, valbatchnums), f, protocol=2)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. get_data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_index(self, data_dict, setname, ifshuffle=True):\n",
    "    '''\n",
    "    Get the dataset sampling index.\n",
    "    data_index:\n",
    "        --> First row: frame id in set\n",
    "        --> which set\n",
    "        --> new frame id, all scenes\n",
    "    '''\n",
    "    set_id = [] # which scene is the frame of frame_id_in_set related to\n",
    "    frame_id_in_set = [] # frames in all train/test scenes\n",
    "    total_frame = 0 # total number of frames in train/test scenes\n",
    "    \n",
    "    for seti, dict in enumerate(data_dict):\n",
    "        frames = sorted(dict)\n",
    "        maxframe = max(frames) - self.args.seq_length\n",
    "        ####### TOCHECK\n",
    "        ####### Why are we subtracting 20 frames and not 20 timesteps?!\n",
    "        ####!!!!!### maxframe = max(frames) - self.args.seq_length*(frames[1] - frames[0])\n",
    "        frames = [x for x in frames if not x > maxframe]\n",
    "        total_frame += len(frames)\n",
    "        set_id.extend(list(seti for i in range(len(frames))))\n",
    "        frame_id_in_set.extend(list(frames[i] for i in range(len(frames))))\n",
    "\n",
    "    all_frame_id_list = list(i for i in range(total_frame))\n",
    "\n",
    "    data_index = np.concatenate((np.array([frame_id_in_set], dtype=int), np.array([set_id], dtype=int),\n",
    "                                 np.array([all_frame_id_list], dtype=int)), 0)\n",
    "    if ifshuffle:\n",
    "        random.Random().shuffle(all_frame_id_list)\n",
    "    data_index = data_index[:, all_frame_id_list]\n",
    "\n",
    "    # to make full use of the data. Add again at the end the fisrt #batch_size frames\n",
    "    if setname == 'train':\n",
    "        data_index = np.append(data_index, data_index[:, :self.args.batch_size], 1)\n",
    "    return data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = get_data_index(self, frameped_dict, setname, ifshuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_index:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7500, 7510,  780,  786,  792,  798,  804,  810,  816],\n",
       "       [   6,    6,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [6092, 6093,    0,    1,    2,    3,    4,    5,    6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"data_index:\")\n",
    "data_index[:,-10:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. find_trajectory_fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trajectory_fragment(trajectory, startframe, seq_length, skip):\n",
    "    '''\n",
    "    Query the trajectory fragment based on the index. Replace with 0 if data does not exist.\n",
    "    '''\n",
    "    return_trajec = np.zeros((seq_length, 3))\n",
    "    endframe = startframe + (seq_length) * skip\n",
    "    start_n = np.where(trajectory[:, 0] == startframe)\n",
    "    end_n = np.where(trajectory[:, 0] == endframe)\n",
    "    iffull = False\n",
    "    ifexsitobs = False\n",
    "\n",
    "    if start_n[0].shape[0] == 0 and end_n[0].shape[0] != 0:\n",
    "        start_n = 0\n",
    "        end_n = end_n[0][0]\n",
    "        if end_n == 0:\n",
    "            return return_trajec, iffull, ifexsitobs\n",
    "\n",
    "    elif end_n[0].shape[0] == 0 and start_n[0].shape[0] != 0:\n",
    "        start_n = start_n[0][0]\n",
    "        end_n = trajectory.shape[0]\n",
    "\n",
    "    elif end_n[0].shape[0] == 0 and start_n[0].shape[0] == 0:\n",
    "        start_n = 0\n",
    "        end_n = trajectory.shape[0]\n",
    "\n",
    "    else:\n",
    "        end_n = end_n[0][0]\n",
    "        start_n = start_n[0][0]\n",
    "\n",
    "    candidate_seq = trajectory[start_n:end_n]\n",
    "    offset_start = int((candidate_seq[0, 0] - startframe) // skip)\n",
    "\n",
    "    offset_end = self.args.seq_length + int((candidate_seq[-1, 0] - endframe) // skip)\n",
    "\n",
    "    return_trajec[offset_start:offset_end + 1, :3] = candidate_seq\n",
    "\n",
    "    if return_trajec[self.args.obs_length - 1, 1] != 0:\n",
    "        ifexsitobs = True\n",
    "\n",
    "    if offset_end - offset_start >= seq_length - 1:\n",
    "        iffull = True\n",
    "\n",
    "    return return_trajec, iffull, ifexsitobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. get_seq_from_index_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_from_index_balance(self, frameped_dict, pedtraject_dict, data_index, setname):\n",
    "    '''\n",
    "    Query the trajectories fragments from data sampling index.\n",
    "    Notes: Divide the scene if there are too many people; accumulate the scene if there are few people.\n",
    "    This function takes less gpu memory.\n",
    "    '''\n",
    "    batch_data_mass = []\n",
    "    batch_data = []\n",
    "    Batch_id = []\n",
    "\n",
    "    temp = self.args.batch_around_ped\n",
    "    if setname == 'train':\n",
    "        skip = self.trainskip\n",
    "    else:\n",
    "        skip = self.testskip\n",
    "\n",
    "    ped_cnt = 0\n",
    "    last_frame = 0\n",
    "    for i in range(data_index.shape[1]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Processed frames:\", i, '/', data_index.shape[1])\n",
    "        cur_frame, cur_set, _ = data_index[:, i]\n",
    "        framestart_pedi = set(frameped_dict[cur_set][cur_frame])\n",
    "        try:\n",
    "            frameend_pedi = set(frameped_dict[cur_set][cur_frame + self.args.seq_length * skip[cur_set]])\n",
    "        except:\n",
    "            continue\n",
    "        present_pedi = framestart_pedi | frameend_pedi\n",
    "        if (framestart_pedi & frameend_pedi).__len__() == 0:\n",
    "            continue\n",
    "        traject = ()\n",
    "        IFfull = []\n",
    "        for ped in present_pedi:\n",
    "            cur_trajec, iffull, ifexistobs = find_trajectory_fragment(pedtraject_dict[cur_set][ped], cur_frame,\n",
    "                                                                           self.args.seq_length, skip[cur_set])\n",
    "            if len(cur_trajec) == 0:\n",
    "                continue\n",
    "            if ifexistobs == False:\n",
    "                # Just ignore trajectories if their data don't exsist at the last obversed time step (easy for data shift)\n",
    "                continue\n",
    "            if sum(cur_trajec[:, 0] > 0) < 5:\n",
    "                # filter trajectories have too few frame data\n",
    "                continue\n",
    "\n",
    "            cur_trajec = (cur_trajec[:, 1:].reshape(-1, 1, 2),)\n",
    "            traject = traject.__add__(cur_trajec)\n",
    "            IFfull.append(iffull)\n",
    "        if traject.__len__() < 1:\n",
    "            continue\n",
    "        if sum(IFfull) < 1:\n",
    "            continue\n",
    "        traject_batch = np.concatenate(traject, 1)\n",
    "        batch_pednum = sum([i.shape[1] for i in batch_data]) + traject_batch.shape[1]\n",
    "\n",
    "        cur_pednum = traject_batch.shape[1]\n",
    "        ped_cnt += cur_pednum\n",
    "        batch_id = (cur_set, cur_frame,)\n",
    "\n",
    "        if cur_pednum >= self.args.batch_around_ped * 2:\n",
    "            # too many people in current scene\n",
    "            # split the scene into two batches\n",
    "            ind = traject_batch[self.args.obs_length - 1].argsort(0)\n",
    "            cur_batch_data, cur_Batch_id = [], []\n",
    "            Seq_batchs = [traject_batch[:, ind[:cur_pednum // 2, 0]], traject_batch[:, ind[cur_pednum // 2:, 0]]]\n",
    "            for sb in Seq_batchs:\n",
    "                cur_batch_data.append(sb)\n",
    "                cur_Batch_id.append(batch_id)\n",
    "                cur_batch_data = massup_batch(cur_batch_data)\n",
    "                batch_data_mass.append((cur_batch_data, cur_Batch_id,))\n",
    "                cur_batch_data = []\n",
    "                cur_Batch_id = []\n",
    "\n",
    "            last_frame = i\n",
    "        elif cur_pednum >= self.args.batch_around_ped:\n",
    "            # good pedestrian numbers\n",
    "            cur_batch_data, cur_Batch_id = [], []\n",
    "            cur_batch_data.append(traject_batch)\n",
    "            cur_Batch_id.append(batch_id)\n",
    "            cur_batch_data = massup_batch(cur_batch_data)\n",
    "            batch_data_mass.append((cur_batch_data, cur_Batch_id,))\n",
    "\n",
    "            last_frame = i\n",
    "        else:  # less pedestrian numbers <64\n",
    "            # accumulate multiple framedata into a batch\n",
    "            if batch_pednum > self.args.batch_around_ped:\n",
    "                # enough people in the scene\n",
    "                batch_data.append(traject_batch)\n",
    "                Batch_id.append(batch_id)\n",
    "\n",
    "                batch_data = massup_batch(batch_data)\n",
    "                batch_data_mass.append((batch_data, Batch_id,))\n",
    "\n",
    "                last_frame = i\n",
    "                batch_data = []\n",
    "                Batch_id = []\n",
    "            else:\n",
    "                batch_data.append(traject_batch)\n",
    "                Batch_id.append(batch_id)\n",
    "\n",
    "    if last_frame < data_index.shape[1] - 1 and setname == 'test' and batch_pednum > 1:\n",
    "        batch_data = massup_batch(batch_data)\n",
    "        batch_data_mass.append((batch_data, Batch_id,))\n",
    "    self.args.batch_around_ped = temp\n",
    "    return batch_data_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massup_batch(batch_data):\n",
    "    '''\n",
    "    Massed up data fragements in different time window together to a batch\n",
    "    '''\n",
    "    num_Peds = 0\n",
    "    for batch in batch_data:\n",
    "        num_Peds += batch.shape[1]\n",
    "\n",
    "    seq_list_b = np.zeros((self.args.seq_length, 0))\n",
    "    nodes_batch_b = np.zeros((self.args.seq_length, 0, 2))\n",
    "    nei_list_b = np.zeros((self.args.seq_length, num_Peds, num_Peds))\n",
    "    nei_num_b = np.zeros((self.args.seq_length, num_Peds))\n",
    "    num_Ped_h = 0\n",
    "    batch_pednum = []\n",
    "    for batch in batch_data:\n",
    "        num_Ped = batch.shape[1]\n",
    "        seq_list, nei_list, nei_num = get_social_inputs_numpy(batch)\n",
    "        nodes_batch_b = np.append(nodes_batch_b, batch, 1)\n",
    "        seq_list_b = np.append(seq_list_b, seq_list, 1)\n",
    "        nei_list_b[:, num_Ped_h:num_Ped_h + num_Ped, num_Ped_h:num_Ped_h + num_Ped] = nei_list\n",
    "        nei_num_b[:, num_Ped_h:num_Ped_h + num_Ped] = nei_num\n",
    "        batch_pednum.append(num_Ped)\n",
    "        num_Ped_h += num_Ped\n",
    "    return (nodes_batch_b, seq_list_b, nei_list_b, nei_num_b, batch_pednum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_social_inputs_numpy(inputnodes):\n",
    "    '''\n",
    "    Get the sequence list (denoting where data exsist) and neighboring list (denoting where neighbors exsist).\n",
    "    '''\n",
    "    num_Peds = inputnodes.shape[1]\n",
    "\n",
    "    seq_list = np.zeros((inputnodes.shape[0], num_Peds))\n",
    "    # denote where data not missing\n",
    "\n",
    "    for pedi in range(num_Peds):\n",
    "        seq = inputnodes[:, pedi]\n",
    "        seq_list[seq[:, 0] != 0, pedi] = 1\n",
    "\n",
    "    # get relative cords, neighbor id list\n",
    "    nei_list = np.zeros((inputnodes.shape[0], num_Peds, num_Peds))\n",
    "    nei_num = np.zeros((inputnodes.shape[0], num_Peds))\n",
    "\n",
    "    # nei_list[f,i,j] denote if j is i's neighbors in frame f\n",
    "    for pedi in range(num_Peds):\n",
    "        nei_list[:, pedi, :] = seq_list\n",
    "        nei_list[:, pedi, pedi] = 0  # person i is not the neighbor of itself\n",
    "        nei_num[:, pedi] = np.sum(nei_list[:, pedi, :], 1)\n",
    "        seqi = inputnodes[:, pedi]\n",
    "        for pedj in range(num_Peds):\n",
    "            seqj = inputnodes[:, pedj]\n",
    "            select = (seq_list[:, pedi] > 0) & (seq_list[:, pedj] > 0)\n",
    "\n",
    "            relative_cord = seqi[select, :2] - seqj[select, :2]\n",
    "\n",
    "            # invalid data index\n",
    "            select_dist = (abs(relative_cord[:, 0]) > self.args.neighbor_thred) | (\n",
    "                    abs(relative_cord[:, 1]) > self.args.neighbor_thred)\n",
    "\n",
    "            nei_num[select, pedi] -= select_dist\n",
    "\n",
    "            select[select == True] = select_dist\n",
    "            nei_list[select, pedi, pedj] = 0\n",
    "    return seq_list, nei_list, nei_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute find_trajectory_fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_set = 0\n",
    "ped = 3\n",
    "cur_frame = 804 # for ped2 --> 804: True-True, 912: False-False, 1024: Error\n",
    "cur_frame = 912\n",
    "\n",
    "if setname == 'train':\n",
    "    skip = self.trainskip\n",
    "elif setname == 'test':\n",
    "    skip = self.testskip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iffull: False\n",
      "ifexistobs: False\n",
      "trajectory_fragment shape: (20, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.1200e+02,  7.0111e+00,  6.1392e+00],\n",
       "       [ 9.1800e+02,  7.0778e+00,  5.7418e+00],\n",
       "       [ 9.2400e+02,  7.1425e+00,  5.3854e+00],\n",
       "       [ 9.3000e+02,  7.0356e+00,  5.0606e+00],\n",
       "       [ 9.3600e+02,  6.9620e+00,  4.8729e+00],\n",
       "       [ 9.4200e+02,  7.0212e+00,  4.6004e+00],\n",
       "       [ 9.4800e+02,  6.9870e+00,  4.4592e+00],\n",
       "       [ 9.5400e+02,  7.0495e+00,  4.1372e+00],\n",
       "       [ 9.6000e+02,  6.9863e+00,  3.7569e+00],\n",
       "       [ 9.6600e+02,  6.9629e+00,  3.4230e+00],\n",
       "       [ 9.7200e+02,  6.8523e+00,  3.0802e+00],\n",
       "       [ 9.7800e+02,  7.0434e+00,  2.8041e+00],\n",
       "       [ 9.8400e+02,  7.2976e+00,  2.2372e+00],\n",
       "       [ 9.9000e+02,  7.1490e+00,  1.7815e+00],\n",
       "       [ 9.9600e+02,  6.9985e+00,  1.3200e+00],\n",
       "       [ 1.0020e+03,  6.9355e+00,  8.5965e-01],\n",
       "       [ 1.0080e+03,  6.9255e+00,  2.4332e-01],\n",
       "       [ 1.0140e+03,  6.8641e+00, -2.8205e-01],\n",
       "       [ 1.0200e+03,  6.6592e+00, -7.2057e-01],\n",
       "       [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_trajec, iffull, ifexistobs = find_trajectory_fragment(pedtraject_dict[cur_set][ped], cur_frame,\n",
    "                                                                           self.args.seq_length, skip[cur_set])\n",
    "print(\"iffull:\", iffull)\n",
    "print(\"ifexistobs:\", ifexistobs)\n",
    "print(\"trajectory_fragment shape:\", cur_trajec.shape)\n",
    "cur_trajec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trajectory:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8.3400e+02,  6.6684e+00,  1.2271e+01],\n",
       "       [ 8.4000e+02,  6.7666e+00,  1.1936e+01],\n",
       "       [ 8.4600e+02,  6.9144e+00,  1.1448e+01],\n",
       "       [ 8.5200e+02,  6.7983e+00,  1.0826e+01],\n",
       "       [ 8.5800e+02,  6.7861e+00,  1.0394e+01],\n",
       "       [ 8.6400e+02,  6.8606e+00,  9.8409e+00],\n",
       "       [ 8.7000e+02,  6.8512e+00,  9.3565e+00],\n",
       "       [ 8.7600e+02,  6.7963e+00,  8.9454e+00],\n",
       "       [ 8.8200e+02,  6.8699e+00,  8.4109e+00],\n",
       "       [ 8.8800e+02,  6.8577e+00,  7.9486e+00],\n",
       "       [ 8.9400e+02,  6.8070e+00,  7.4355e+00],\n",
       "       [ 9.0000e+02,  6.8356e+00,  6.9627e+00],\n",
       "       [ 9.0600e+02,  6.9838e+00,  6.5785e+00],\n",
       "       [ 9.1200e+02,  7.0111e+00,  6.1392e+00],\n",
       "       [ 9.1800e+02,  7.0778e+00,  5.7418e+00],\n",
       "       [ 9.2400e+02,  7.1425e+00,  5.3854e+00],\n",
       "       [ 9.3000e+02,  7.0356e+00,  5.0606e+00],\n",
       "       [ 9.3600e+02,  6.9620e+00,  4.8729e+00],\n",
       "       [ 9.4200e+02,  7.0212e+00,  4.6004e+00],\n",
       "       [ 9.4800e+02,  6.9870e+00,  4.4592e+00],\n",
       "       [ 9.5400e+02,  7.0495e+00,  4.1372e+00],\n",
       "       [ 9.6000e+02,  6.9863e+00,  3.7569e+00],\n",
       "       [ 9.6600e+02,  6.9629e+00,  3.4230e+00],\n",
       "       [ 9.7200e+02,  6.8523e+00,  3.0802e+00],\n",
       "       [ 9.7800e+02,  7.0434e+00,  2.8041e+00],\n",
       "       [ 9.8400e+02,  7.2976e+00,  2.2372e+00],\n",
       "       [ 9.9000e+02,  7.1490e+00,  1.7815e+00],\n",
       "       [ 9.9600e+02,  6.9985e+00,  1.3200e+00],\n",
       "       [ 1.0020e+03,  6.9355e+00,  8.5965e-01],\n",
       "       [ 1.0080e+03,  6.9255e+00,  2.4332e-01],\n",
       "       [ 1.0140e+03,  6.8641e+00, -2.8205e-01],\n",
       "       [ 1.0200e+03,  6.6592e+00, -7.2057e-01]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Full trajectory:\")\n",
    "pedtraject_dict[cur_set][ped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute get_seq_from_index_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames: 0 / 6102\n",
      "Frames: 100 / 6102\n",
      "Frames: 200 / 6102\n",
      "Frames: 300 / 6102\n",
      "Frames: 400 / 6102\n",
      "Frames: 500 / 6102\n",
      "Frames: 600 / 6102\n",
      "Frames: 700 / 6102\n",
      "Frames: 800 / 6102\n",
      "Frames: 900 / 6102\n",
      "Frames: 1000 / 6102\n",
      "Frames: 1100 / 6102\n",
      "Frames: 1200 / 6102\n",
      "Frames: 1300 / 6102\n",
      "Frames: 1400 / 6102\n",
      "Frames: 1500 / 6102\n",
      "Frames: 1600 / 6102\n",
      "Frames: 1700 / 6102\n",
      "Frames: 1800 / 6102\n",
      "Frames: 1900 / 6102\n",
      "Frames: 2000 / 6102\n",
      "Frames: 2100 / 6102\n",
      "Frames: 2200 / 6102\n",
      "Frames: 2300 / 6102\n",
      "Frames: 2400 / 6102\n",
      "Frames: 2500 / 6102\n",
      "Frames: 2600 / 6102\n",
      "Frames: 2700 / 6102\n",
      "Frames: 2800 / 6102\n",
      "Frames: 2900 / 6102\n",
      "Frames: 3000 / 6102\n",
      "Frames: 3100 / 6102\n",
      "Frames: 3200 / 6102\n",
      "Frames: 3300 / 6102\n",
      "Frames: 3400 / 6102\n",
      "Frames: 3500 / 6102\n",
      "Frames: 3600 / 6102\n",
      "Frames: 3700 / 6102\n",
      "Frames: 3800 / 6102\n",
      "Frames: 3900 / 6102\n",
      "Frames: 4000 / 6102\n",
      "Frames: 4100 / 6102\n",
      "Frames: 4200 / 6102\n",
      "Frames: 4300 / 6102\n",
      "Frames: 4400 / 6102\n",
      "Frames: 4500 / 6102\n",
      "Frames: 4600 / 6102\n",
      "Frames: 4700 / 6102\n",
      "Frames: 4800 / 6102\n",
      "Frames: 4900 / 6102\n",
      "Frames: 5000 / 6102\n",
      "Frames: 5100 / 6102\n",
      "Frames: 5200 / 6102\n",
      "Frames: 5300 / 6102\n",
      "Frames: 5400 / 6102\n",
      "Frames: 5500 / 6102\n",
      "Frames: 5600 / 6102\n",
      "Frames: 5700 / 6102\n",
      "Frames: 5800 / 6102\n",
      "Frames: 5900 / 6102\n",
      "Frames: 6000 / 6102\n",
      "Frames: 6100 / 6102\n",
      "Number of bathes: 209\n"
     ]
    }
   ],
   "source": [
    "batch_data_mass = get_seq_from_index_balance(self, frameped_dict, pedtraject_dict, data_index, setname)\n",
    "trainbatchnums = len(batch_data_mass)\n",
    "print(\"Number of bathes:\", trainbatchnums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, batch_id = batch_data_mass[0] # first batch\n",
    "batch_id  # list of tuples of integers, len = 40\n",
    "batch_abs, seq_list, nei_list, nei_num, batch_pednum = batch  # batch_norm, shift_value are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frames: 0 / 6102\n",
      "Processed frames: 100 / 6102\n",
      "Processed frames: 200 / 6102\n",
      "Processed frames: 300 / 6102\n",
      "Processed frames: 400 / 6102\n",
      "Processed frames: 500 / 6102\n",
      "Processed frames: 600 / 6102\n",
      "Processed frames: 700 / 6102\n",
      "Processed frames: 800 / 6102\n",
      "Processed frames: 900 / 6102\n",
      "Processed frames: 1000 / 6102\n",
      "Processed frames: 1100 / 6102\n",
      "Processed frames: 1200 / 6102\n",
      "Processed frames: 1300 / 6102\n",
      "Processed frames: 1400 / 6102\n",
      "Processed frames: 1500 / 6102\n",
      "Processed frames: 1600 / 6102\n",
      "Processed frames: 1700 / 6102\n",
      "Processed frames: 1800 / 6102\n",
      "Processed frames: 1900 / 6102\n",
      "Processed frames: 2000 / 6102\n",
      "Processed frames: 2100 / 6102\n",
      "Processed frames: 2200 / 6102\n",
      "Processed frames: 2300 / 6102\n",
      "Processed frames: 2400 / 6102\n",
      "Processed frames: 2500 / 6102\n",
      "Processed frames: 2600 / 6102\n",
      "Processed frames: 2700 / 6102\n",
      "Processed frames: 2800 / 6102\n",
      "Processed frames: 2900 / 6102\n",
      "Processed frames: 3000 / 6102\n",
      "Processed frames: 3100 / 6102\n",
      "Processed frames: 3200 / 6102\n",
      "Processed frames: 3300 / 6102\n",
      "Processed frames: 3400 / 6102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-3de3ec7767ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mBatch_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmassup_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mbatch_data_mass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-22317a717c67>\u001b[0m in \u001b[0;36mmassup_batch\u001b[0;34m(batch_data)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnum_Ped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mseq_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnei_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnei_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_social_inputs_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mnodes_batch_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_batch_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mseq_list_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_list_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e50a5c121f5b>\u001b[0m in \u001b[0;36mget_social_inputs_numpy\u001b[0;34m(inputnodes)\u001b[0m\n\u001b[1;32m     32\u001b[0m                     abs(relative_cord[:, 1]) > self.args.neighbor_thred)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mnei_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpedi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mselect_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mselect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "        IFfull.append(iffull)\n",
    "    if traject.__len__() < 1:\n",
    "        continue\n",
    "    if sum(IFfull) < 1:\n",
    "        continue\n",
    "    traject_batch = np.concatenate(traject, 1)\n",
    "    batch_pednum = sum([i.shape[1] for i in batch_data]) + traject_batch.shape[1]\n",
    "\n",
    "    cur_pednum = traject_batch.shape[1]\n",
    "    ped_cnt += cur_pednum\n",
    "    batch_id = (cur_set, cur_frame,)\n",
    "\n",
    "    if cur_pednum >= self.args.batch_around_ped * 2:\n",
    "        # too many people in current scene\n",
    "        # split the scene into two batches\n",
    "        ind = traject_batch[self.args.obs_length - 1].argsort(0)\n",
    "        cur_batch_data, cur_Batch_id = [], []\n",
    "        Seq_batchs = [traject_batch[:, ind[:cur_pednum // 2, 0]], traject_batch[:, ind[cur_pednum // 2:, 0]]]\n",
    "        for sb in Seq_batchs:\n",
    "            cur_batch_data.append(sb)\n",
    "            cur_Batch_id.append(batch_id)\n",
    "            cur_batch_data = massup_batch(cur_batch_data)\n",
    "            batch_data_mass.append((cur_batch_data, cur_Batch_id,))\n",
    "            cur_batch_data = []\n",
    "            cur_Batch_id = []\n",
    "\n",
    "        last_frame = i\n",
    "    elif cur_pednum >= self.args.batch_around_ped:\n",
    "        # good pedestrian numbers\n",
    "        cur_batch_data, cur_Batch_id = [], []\n",
    "        cur_batch_data.append(traject_batch)\n",
    "        cur_Batch_id.append(batch_id)\n",
    "        cur_batch_data = massup_batch(cur_batch_data)\n",
    "        batch_data_mass.append((cur_batch_data, cur_Batch_id,))\n",
    "\n",
    "        last_frame = i\n",
    "    else:  # less pedestrian numbers <64\n",
    "        # accumulate multiple framedata into a batch\n",
    "        if batch_pednum > self.args.batch_around_ped:\n",
    "            # enough people in the scene\n",
    "            batch_data.append(traject_batch)\n",
    "            Batch_id.append(batch_id)\n",
    "\n",
    "            batch_data = massup_batch(batch_data)\n",
    "            batch_data_mass.append((batch_data, Batch_id,))\n",
    "\n",
    "            last_frame = i\n",
    "            batch_data = []\n",
    "            Batch_id = []\n",
    "        else:\n",
    "            batch_data.append(traject_batch)\n",
    "            Batch_id.append(batch_id)\n",
    "\n",
    "if last_frame < data_index.shape[1] - 1 and setname == 'test' and batch_pednum > 1:\n",
    "    batch_data = massup_batch(batch_data)\n",
    "    batch_data_mass.append((batch_data, Batch_id,))\n",
    "self.args.batch_around_ped = temp\n",
    "# return batch_data_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frames: 0 / 6102\n"
     ]
    }
   ],
   "source": [
    "# def get_seq_from_index_balance(\n",
    "# self, frameped_dict, pedtraject_dict, data_index, setname):\n",
    "\n",
    "batch_data_mass = []\n",
    "batch_data = []\n",
    "Batch_id = []\n",
    "\n",
    "temp = self.args.batch_around_ped\n",
    "if setname == 'train':\n",
    "    skip = self.trainskip\n",
    "else:\n",
    "    skip = self.testskip\n",
    "\n",
    "ped_cnt = 0\n",
    "last_frame = 0\n",
    "\n",
    "# loop over frames\n",
    "for i in range(2):\n",
    "    if i % 100 == 0:\n",
    "        print(\"Processed frames:\", i, '/', data_index.shape[1])\n",
    "    cur_frame, cur_set, _ = data_index[:, i]\n",
    "    # pedestrians in the start frame\n",
    "    framestart_pedi = set(frameped_dict[cur_set][cur_frame])\n",
    "    try:\n",
    "        # pedestrians in the end frame (+20 frames)\n",
    "        frameend_pedi = set(frameped_dict[cur_set][cur_frame + self.args.seq_length * skip[cur_set]])\n",
    "    except:\n",
    "        # skip if no pedestrians or any problem\n",
    "        continue\n",
    "    # pedestrians present in the currents 20 frames\n",
    "    present_pedi = framestart_pedi | frameend_pedi\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # if the initial pedestrians all disappers after 20 frames\n",
    "    if (framestart_pedi & frameend_pedi).__len__() == 0:\n",
    "        continue\n",
    "    traject = ()\n",
    "    IFfull = []\n",
    "    # loop over the pedestrians in the start frame (and possibly beyond)\n",
    "    for ped in present_pedi:\n",
    "        cur_trajec, iffull, ifexistobs = find_trajectory_fragment(pedtraject_dict[cur_set][ped], cur_frame,\n",
    "                                                                       self.args.seq_length, skip[cur_set])\n",
    "        if len(cur_trajec) == 0:\n",
    "            continue\n",
    "        if ifexistobs == False:\n",
    "            # Just ignore trajectories if their data don't exsist at the last obversed time step (easy for data shift)\n",
    "            continue\n",
    "        if sum(cur_trajec[:, 0] > 0) < 5:\n",
    "            # filter trajectories have too few frame data\n",
    "            continue\n",
    "\n",
    "        cur_trajec = (cur_trajec[:, 1:].reshape(-1, 1, 2),)\n",
    "        traject = traject.__add__(cur_trajec)\n",
    "        IFfull.append(iffull)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, False, False]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.1734, 6.0058]],\n",
       "\n",
       "       [[5.1737, 6.0054]],\n",
       "\n",
       "       [[5.1737, 6.0048]],\n",
       "\n",
       "       [[5.1739, 6.0044]],\n",
       "\n",
       "       [[5.1739, 6.0037]],\n",
       "\n",
       "       [[5.1739, 6.0033]],\n",
       "\n",
       "       [[5.1741, 6.0027]],\n",
       "\n",
       "       [[5.1741, 6.0023]],\n",
       "\n",
       "       [[5.1744, 6.0016]],\n",
       "\n",
       "       [[5.1744, 6.001 ]],\n",
       "\n",
       "       [[5.1746, 6.0006]],\n",
       "\n",
       "       [[5.1746, 5.9999]],\n",
       "\n",
       "       [[5.1746, 5.9995]],\n",
       "\n",
       "       [[5.1749, 5.9989]],\n",
       "\n",
       "       [[5.1749, 5.9985]],\n",
       "\n",
       "       [[5.1751, 5.9978]],\n",
       "\n",
       "       [[5.1751, 5.9972]],\n",
       "\n",
       "       [[5.1753, 5.9968]],\n",
       "\n",
       "       [[5.1753, 5.9962]],\n",
       "\n",
       "       [[5.1753, 5.9957]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traject[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
