{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with src/utils.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((3,4))\n",
    "a.dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 getLossMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossMask(outputs, node_first, seq_list, using_cuda=False):\n",
    "    '''\n",
    "    Get a mask to denote whether both of current and previous data exsist.\n",
    "    Note: It is not supposed to calculate loss for a person at time t if his data at t-1 does not exsist.\n",
    "    '''\n",
    "\n",
    "    if outputs.dim() == 3:\n",
    "        seq_length = outputs.shape[0]\n",
    "    else:\n",
    "        seq_length = outputs.shape[1]\n",
    "\n",
    "    node_pre = node_first\n",
    "    lossmask = torch.zeros(seq_length, seq_list.shape[1])\n",
    "\n",
    "    if using_cuda:\n",
    "        lossmask = lossmask.cuda()\n",
    "\n",
    "    # For loss mask, only generate for those exist through the whole window\n",
    "    for framenum in range(seq_length):\n",
    "        if framenum == 0:\n",
    "            lossmask[framenum] = seq_list[framenum] * node_pre\n",
    "        else:\n",
    "            lossmask[framenum] = seq_list[framenum] * lossmask[framenum - 1]\n",
    "\n",
    "    return lossmask, sum(sum(lossmask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. L2forTest deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2forTest(outputs, targets, obs_length, lossMask):\n",
    "    '''\n",
    "    Evaluation.\n",
    "    '''\n",
    "    seq_length = outputs.shape[0]\n",
    "    error = torch.norm(outputs - targets, p=2, dim=2)\n",
    "    # only calculate the pedestrian presents fully presented in the time window\n",
    "    pedi_full = torch.sum(lossMask, dim=0) == seq_length\n",
    "    error_full = error[obs_length - 1:, pedi_full]\n",
    "    error = torch.sum(error_full)\n",
    "    error_cnt = error_full.numel()\n",
    "    final_error = torch.sum(error_full[-1])\n",
    "    final_error_cnt = error_full[-1].numel()\n",
    "\n",
    "    return error.item(), error_cnt, final_error.item(), final_error_cnt, error_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. L2forTest stocastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2forTestS(outputs, targets, obs_length, lossMask, num_samples=20):\n",
    "    '''\n",
    "    Evaluation, stochastic version\n",
    "    '''\n",
    "    seq_length = outputs.shape[1]\n",
    "    error = torch.norm(outputs - targets, p=2, dim=3)\n",
    "    # only calculate the pedestrian presents fully presented in the time window\n",
    "    pedi_full = torch.sum(lossMask, dim=0) == seq_length\n",
    "    error_full = error[:, obs_length - 1:, pedi_full]\n",
    "\n",
    "    error_full_sum = torch.sum(error_full, dim=1)\n",
    "    error_full_sum_min, min_index = torch.min(error_full_sum, dim=0)\n",
    "\n",
    "    best_error = []\n",
    "    for index, value in enumerate(min_index):\n",
    "        best_error.append(error_full[value, :, index])\n",
    "    best_error = torch.stack(best_error)\n",
    "    best_error = best_error.permute(1, 0)\n",
    "\n",
    "    error = torch.sum(error_full_sum_min)\n",
    "    error_cnt = error_full.numel() / num_samples\n",
    "\n",
    "    final_error = torch.sum(best_error[-1])\n",
    "    final_error_cnt = error_full.shape[-1]\n",
    "\n",
    "    return error.item(), error_cnt, final_error.item(), final_error_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
